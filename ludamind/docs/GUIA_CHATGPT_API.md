# Gu√≠a: C√≥mo Garantizar Routing Correcto con ChatGPT API

## üéØ El Problema

Cuando usas ChatGPT por API, **cada llamada es independiente**. No hay memoria entre llamadas.

| M√©todo | Memoria | Costo Tokens | Implementaci√≥n |
|--------|---------|--------------|----------------|
| **Chat Web** | ‚úÖ Guarda contexto | Solo primera vez | Manual |
| **API** | ‚ùå Sin memoria | En cada llamada | Autom√°tico |

**El problema**: Si entrenas ChatGPT en una conversaci√≥n web, ese entrenamiento **NO se transfiere** a las llamadas API.

---

## üí° Soluciones

### **Opci√≥n 1: System Prompt en Cada Llamada** ‚≠ê RECOMENDADO

**Ventajas:**
- ‚úÖ Funciona inmediatamente
- ‚úÖ F√°cil de actualizar
- ‚úÖ Sin costo adicional de entrenamiento
- ‚úÖ Consistente en cada llamada

**Desventajas:**
- ‚ö†Ô∏è Consume ~600 tokens por llamada (~$0.001/llamada con GPT-4)
- ‚ö†Ô∏è Ligeramente m√°s lento

**C√≥mo funciona:**
```python
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {
            "role": "system",
            "content": LUDAFARMA_SYSTEM_PROMPT  # ‚Üê Se incluye en CADA llamada
        },
        {
            "role": "user",
            "content": "GMV de Glovo √∫ltima semana"
        }
    ]
)
```

**Archivo**: `EJEMPLO_USO_API.py` (l√≠neas 17-64)

---

### **Opci√≥n 2: Fine-Tuning**

**Ventajas:**
- ‚úÖ Modelo permanentemente entrenado
- ‚úÖ No consume tokens del system prompt
- ‚úÖ Respuestas m√°s r√°pidas
- ‚úÖ M√°s preciso para casos complejos

**Desventajas:**
- ‚ùå Costo inicial de entrenamiento (~$10-20)
- ‚ùå Necesita m√≠nimo 10 ejemplos de calidad
- ‚ùå M√°s dif√≠cil de actualizar
- ‚ùå Costo por uso del modelo fine-tuneado

**C√≥mo funciona:**
1. Crear dataset de entrenamiento (archivo `.jsonl`)
2. Subir a OpenAI
3. Entrenar modelo (toma ~20 minutos)
4. Usar el modelo personalizado

**Archivo**: `FINE_TUNING_DATASET.jsonl` (20 ejemplos listos)

**Comandos:**
```bash
# 1. Subir dataset
openai files create -f FINE_TUNING_DATASET.jsonl -p fine-tune

# 2. Crear fine-tuning job
openai fine-tuning create -t <file-id> -m gpt-3.5-turbo

# 3. Usar modelo entrenado
openai.ChatCompletion.create(
    model="ft:gpt-3.5-turbo:tu-org:modelo-luda:abc123",
    messages=[{"role": "user", "content": "GMV de Glovo"}]
)
```

---

### **Opci√≥n 3: H√≠brido** (System Prompt Compacto)

**Mejor de ambos mundos:**
- System prompt MUY corto (~100 tokens vs 600)
- Solo incluye la regla esencial

**Archivo**: `EJEMPLO_USO_API.py` (l√≠neas 114-124)

```python
COMPACT_PROMPT = """Routing LudaFarma:
MongoDB si menciona: Glovo, Uber, Danone, Carrefour, shortage, derivaci√≥n
MySQL si NO menciona canal (analytics general)

Partners (MongoDB): users.findOne({idUser}), luego bookings.creator
Shortage (MongoDB): bookings.origin EXISTS
GMV: SUM(items[].pvp * quantity)"""
```

**Ventajas:**
- ‚úÖ Solo ~$0.0002/llamada (5x m√°s barato)
- ‚úÖ Suficiente para casos simples
- ‚úÖ M√°s r√°pido que versi√≥n completa

**Desventajas:**
- ‚ö†Ô∏è Menos contexto, puede fallar en casos complejos

---

## üìä Comparaci√≥n de Costos

| Opci√≥n | Costo Setup | Costo por Llamada | Total (1000 llamadas) |
|--------|-------------|-------------------|----------------------|
| **System Prompt Completo** | $0 | ~$0.001 | **$1.00** |
| **System Prompt Compacto** | $0 | ~$0.0002 | **$0.20** |
| **Fine-Tuning** | $10-20 | ~$0.0005 | **$10.50** |

*Precios estimados con GPT-4. GPT-3.5-turbo es ~10x m√°s barato.*

---

## üéØ Recomendaci√≥n por Caso de Uso

### **Si haces < 10,000 llamadas/mes:**
‚Üí **Opci√≥n 1**: System Prompt Completo
- M√°s f√°cil de implementar
- M√°s flexible para actualizar
- Costo total bajo

### **Si haces > 10,000 llamadas/mes:**
‚Üí **Opci√≥n 2**: Fine-Tuning
- Ahorro significativo en tokens
- Modelo m√°s preciso
- Vale la pena la inversi√≥n inicial

### **Si necesitas respuesta r√°pida:**
‚Üí **Opci√≥n 3**: System Prompt Compacto
- M√≠nimo overhead
- Funciona para casos simples
- Muy econ√≥mico

---

## üöÄ Implementaci√≥n Paso a Paso

### OPCI√ìN 1: System Prompt (M√°s Simple)

**Paso 1:** Copia el system prompt
```bash
# Abre el archivo
notepad C:\Users\dgfre\Documents\trends_mcp\docs\API_SYSTEM_PROMPT.txt
```

**Paso 2:** √ösalo en tu c√≥digo
```python
# Ver archivo completo: EJEMPLO_USO_API.py
from openai import ChatCompletion

SYSTEM_PROMPT = """[Copiar contenido de API_SYSTEM_PROMPT.txt]"""

response = ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": query_del_usuario}
    ]
)
```

**Paso 3:** ¬°Listo! Ya funciona.

---

### OPCI√ìN 2: Fine-Tuning (M√°s Avanzado)

**Paso 1:** Preparar dataset
```bash
# Ya est√° listo en:
C:\Users\dgfre\Documents\trends_mcp\docs\FINE_TUNING_DATASET.jsonl
```

**Paso 2:** Subir a OpenAI
```bash
openai files create \
  -f C:\Users\dgfre\Documents\trends_mcp\docs\FINE_TUNING_DATASET.jsonl \
  -p fine-tune
```

**Paso 3:** Crear fine-tuning job
```bash
openai fine-tuning create \
  -t file-abc123 \
  -m gpt-3.5-turbo \
  --suffix "ludafarma-routing"
```

**Paso 4:** Esperar entrenamiento (~20 minutos)
```bash
# Ver progreso
openai fine-tuning list
```

**Paso 5:** Usar modelo entrenado
```python
response = openai.ChatCompletion.create(
    model="ft:gpt-3.5-turbo:tu-org:ludafarma-routing:abc123",
    messages=[
        {"role": "user", "content": "GMV de Glovo"}
    ]
)
# ‚Üê Ya no necesita system prompt, est√° entrenado!
```

---

## ‚úÖ C√≥mo Validar que Funciona

### Test R√°pido (3 preguntas):

```python
# Test 1: Debe elegir MongoDB
test_query("GMV de Glovo √∫ltima semana")
# ‚úÖ Esperado: "MongoDB porque menciona Glovo (canal)"

# Test 2: Debe elegir MySQL
test_query("Ventas totales de Ibuprofeno")
# ‚úÖ Esperado: "MySQL porque no menciona canal"

# Test 3: Debe elegir MongoDB
test_query("Paracetamol en Glovo")
# ‚úÖ Esperado: "MongoDB porque menciona Glovo + producto"
```

**Si las 3 respuestas son correctas ‚Üí ‚úÖ Funciona bien**

---

## üìÇ Archivos de Referencia

| Archivo | Descripci√≥n | Uso |
|---------|-------------|-----|
| `API_SYSTEM_PROMPT.txt` | System prompt completo | Opci√≥n 1 |
| `EJEMPLO_USO_API.py` | C√≥digo Python de ejemplo | Implementaci√≥n |
| `FINE_TUNING_DATASET.jsonl` | Dataset para fine-tuning | Opci√≥n 2 |
| `CHATGPT_TRAINING_PROMPT.md` | Documentaci√≥n completa | Referencia |

Todos en: `C:\Users\dgfre\Documents\trends_mcp\docs\`

---

## üéì Resumen Ejecutivo

### **Para garantizar que ChatGPT API siempre gestione bien las peticiones:**

**1. Incluir System Prompt en CADA llamada API** (Opci√≥n 1)
   - Es la soluci√≥n m√°s simple y efectiva
   - El prompt se "resetea" en cada llamada
   - Garantiza consistencia

**2. O entrenar un modelo personalizado** (Opci√≥n 2)
   - M√°s costoso pero permanente
   - Mejor para alto volumen

**3. El entrenamiento en chat web NO se transfiere a la API**
   - Son sistemas completamente separados
   - El chat web tiene contexto de conversaci√≥n
   - La API es stateless (sin estado)

### **Soluci√≥n Recomendada:**

```python
# Esto garantiza que SIEMPRE funcione:
SYSTEM_PROMPT = """[Reglas de routing]"""

# En CADA llamada:
openai.ChatCompletion.create(
    messages=[
        {"role": "system", "content": SYSTEM_PROMPT},  # ‚Üê CLAVE
        {"role": "user", "content": user_query}
    ]
)
```

**Costo**: ~$0.001 por llamada (muy econ√≥mico)
**Implementaci√≥n**: 5 minutos
**Mantenimiento**: F√°cil actualizar el prompt

---

## üîó Siguiente Paso

1. **Probar Opci√≥n 1 primero** (System Prompt)
2. Si funciona bien ‚Üí Listo
3. Si tienes alto volumen ‚Üí Considerar Opci√≥n 2 (Fine-tuning)

**C√≥digo listo para usar**: `EJEMPLO_USO_API.py`

---

*Cualquier duda, revisa los ejemplos en los archivos mencionados.*
